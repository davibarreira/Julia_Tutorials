{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89270a25-3f25-4082-adf7-02de3235ad19",
   "metadata": {},
   "source": [
    "# NLP with Julia for Non-English\n",
    "\n",
    "This notebook is a tutorial on how to do NLP tasks in Julia\n",
    "with a twist... We'll deal with non-english documents.\n",
    "The main package for such task is `TextAnalysis.jl`. Yet, there are other functionalities that\n",
    "are not present in Julia. So we use `PythonCall.jl` in order to sprinkle some python in our notebook.\n",
    "\n",
    "In this tutorial, we are going to work with documents in Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bf2384-7cc0-4ff8-b428-65041ab0d4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Main/EMAp/Julia_Tutorials/NLP`\n",
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mFound dependencies: /home/davibarreira/Main/EMAp/Julia_Tutorials/NLP/CondaPkg.toml\n",
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mFound dependencies: /home/davibarreira/.julia/packages/PythonCall/XUf6D/CondaPkg.toml\n",
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mDependencies already up to date\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "\n",
    "using DataFrames\n",
    "ENV[\"COLUMNS\"]=2000\n",
    "using VegaLite\n",
    "using TextAnalysis\n",
    "using TextModels\n",
    "\n",
    "using CondaPkg\n",
    "CondaPkg.add(\"nltk\")\n",
    "CondaPkg.add(\"spacy\")\n",
    "CondaPkg.add(\"ipython\")\n",
    "CondaPkg.add(\"cupy\")\n",
    "using PythonCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c58c4689-1295-4685-a9b9-d55980531271",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b97015-e88a-4afe-9f8d-c435bd738e89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Importing a Corpus\n",
    "\n",
    "To do some NLP analysis, we first need some texts. Hence, let's load a corpus in our notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae1166e-56f1-4b62-9ef8-c34d969ff28d",
   "metadata": {},
   "source": [
    "### 1.1 NLTK\n",
    "\n",
    "We'll use python's nltk package, and the corpus of books from Machado de Assis, a brazilian writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daacc5ae-5066-4b5b-b0fe-1f7decedd198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[1mPython module: \u001b[22m<module 'nltk' from '/home/davibarreira/.local/lib/python3.10/site-packages/nltk/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk = pyimport(\"nltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a687d737-1396-4252-b268-0fb227e8634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package machado to\n",
      "[nltk_data]     /home/davibarreira/nltk_data...\n",
      "[nltk_data]   Package machado is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[1mPython bool: \u001b[22mTrue"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_id = \"machado\"\n",
    "nltk.download(nltk_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9371ccf6-500b-41b7-a44e-92e2a339bcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machado de Assis -- Obra Completa\n",
      "\n",
      "http://machado.mec.gov.br/\n",
      "\n",
      "Public Domain\n",
      "\n",
      "Contents:\n",
      "\n",
      "Romance\n",
      "\n",
      "romance/marm01.txt: Ressurreição (1872)\n",
      "romance/marm02.txt: A Mão e a Luva (1874)\n",
      "romance/marm03.txt: Helena (1876)\n",
      "romance/marm04.txt: Iaiá Garcia (1878)\n",
      "romance/marm05.txt: Memórias Póstumas de Brás Cubas (1881)\n",
      "romance/marm06.txt: Casa Velha (1885)\n",
      "romance/marm07.txt: Quincas Borba (1891)\n",
      "romance/marm08.txt: Dom Casmurro (1899)\n",
      "romance/marm09.txt: Esaú e Jacó (1904)\n",
      "romance/marm10.txt: Memorial de Aires (1908)\n",
      "\n",
      "Poesia\n",
      "\n",
      "poesia/maps01.txt: Crisálidas (1864)\n",
      "poesia/maps02.txt: Falenas (1870)\n",
      "poesia/maps03.txt: Americanas (1875)\n",
      "poesia/maps04.txt: Gazeta de Holanda (1886-88)\n",
      "poesia/maps05.txt: Ocidentais (1901)\n",
      "poesia/maps06.txt: O Almada (1908)\n",
      "poesia/maps07.txt: Dispersas (1854-1939)\n",
      "\n",
      "Contos\n",
      "\n",
      "contos/macn001.txt: Contos Fluminenses (1870); Miss Dollar; Luís Soares; A mulher de preto; O segredo de Augusta; Confissões de uma viúva moça; Linha reta e linha curva; Frei Sim\n",
      "contos/macn002.txt: Histórias da meia-noite (1873); A parasita azul; As bodas de Luís Duarte; Ernesto de Tal; Aurora sem dia; O relógio de ouro; Ponto de vista\n",
      "contos/macn003.txt: Papéis avulsos (1882); O alienista; Teoria do medalhão; A chinela turca; Na arca; D. Benedita; O segredo do bonzo; O anel de Polícrates; O empréstimo; A sereníssima república; O espelho; Uma visita de Alcibíades; Verba testamentária\n",
      "contos/macn004.txt: Histórias sem data (1884); A igreja do Diabo; O lapso; Último capítulo; Cantiga de esponsais; Singular ocorrência; Galeria póstuma; Capítulo dos chapéus; Conto alexandrino; Rimas de Sapucaia!; Uma senhora; Anedota pecuniária; Fulano; A segunda vida; Noite de almirante; Manuscrito de um sacristão; Ex cathedra; A senhora do Galvão; As academias de Sião\n",
      "contos/macn005.txt: Várias histórias (1896); A cartomante; Entre santos; Uns braços; Um homem célebre; A desejada das gentes; A causa secreta; Trio em lá menor; Adão e Eva; O enfermeiro; O diplomático; Mariana; Conto de escola; Um apólogo; D. Paula; Viver!; O cônego ou Metafísica do estilo\n",
      "contos/macn006.txt: Páginas recolhidas (1899); O caso da vara; O dicionário; Um erradio; Eterno!; Missa do galo; Idéias de canário; Lágrimas de Xerxes; Papéis velhos\n",
      "contos/macn007.txt: Relíquias de Casa Velha (1906); Pai contra mãe; Maria Cora; Marcha fúnebre; Um capitão de voluntários; Suje-se gordo!; Umas férias; Evolução; Pílades e Orestes; Anedota do cabriolet\n",
      "\n",
      "Traducao\n",
      "\n",
      "traducao/matr01.txt: Suplício de uma mulher (1865)\n",
      "traducao/matr02.txt: Os trabalhadores do mar (1866)\n",
      "traducao/matr03.txt: Oliver Twist (1870)\n",
      "\n",
      "Teatro\n",
      "\n",
      "teatro/matt01.txt: As forcas caudinas (1956)\n",
      "teatro/matt02.txt: Hoje avental, amanhã luva (1860)\n",
      "teatro/matt03.txt: Desencantos (1861)\n",
      "teatro/matt04.txt: O caminho da porta / O protocolo (1863)\n",
      "teatro/matt05.txt: Quase ministro (1864)\n",
      "teatro/matt06.txt: Os deuses de casaca (1866)\n",
      "teatro/matt07.txt: O bote de rapé (1878)\n",
      "teatro/matt08.txt: Tu, só tu, puro amor (1880)\n",
      "teatro/matt09.txt: Não consultes médico (1899)\n",
      "teatro/matt10.txt: Lição de botânica (1906)\n",
      "\n",
      "Cronica\n",
      "\n",
      "cronica/macr01.txt: Comentários da semana (1861-1863)\n",
      "cronica/macr02.txt: Crônicas do Dr. Semana (1861-1864)\n",
      "cronica/macr03.txt: Crônicas - O futuro (1862-1863)\n",
      "cronica/macr04.txt: Ao acaso (1864-1865)\n",
      "cronica/macr05.txt: Cartas fluminenses (1867)\n",
      "cronica/macr06.txt: Badaladas (1871-1873)\n",
      "cronica/macr07.txt: História de quinze dias (1876-1877)\n",
      "cronica/macr08.txt: História dos trinta dias (1878)\n",
      "cronica/macr09.txt: Notas semanais (1878)\n",
      "cronica/macr10.txt: Balas de estalo (1883-1886)\n",
      "cronica/macr11.txt: Bons dias! (1888-1889)\n",
      "cronica/macr12.txt: A semana (1892-1800)\n",
      "cronica/macr13.txt: O jornal e o livro (1859)\n",
      "cronica/macr14.txt: A reforma pelo jornal (1859)\n",
      "cronica/macr15.txt: Aquarelas (1859)\n",
      "cronica/macr16.txt: O Visconde de Castilho (1875)\n",
      "cronica/macr17.txt: Cherchez la femme (1881)\n",
      "cronica/macr18.txt: José de Alencar (1883)\n",
      "cronica/macr19.txt: Joaquim Serra (1888)\n",
      "cronica/macr20.txt: O futuro dos argentinos (1888)\n",
      "cronica/macr21.txt: Entre 1892 e 1894 (1892-1894)\n",
      "cronica/macr22.txt: Henrique Chaves (1893)\n",
      "cronica/macr23.txt: Henrique Lombaerts (1897)\n",
      "cronica/macr24.txt: O velho Senado (1898)\n",
      "critica/mact01.txt: O Passado, o presente e o futuro da literatura (1858)\n",
      "critica/mact02.txt: Idéias sobre o teatro (1859)\n",
      "critica/mact03.txt: Revista dos teatros (1859)\n",
      "critica/mact04.txt: Revista Dramática (1860)\n",
      "critica/mact05.txt: A Crítica teatral. José de Alencar: Mãe (1860)\n",
      "critica/mact06.txt: Crítica variada - Diário do RJ (1862)\n",
      "critica/mact07.txt: Flores e Frutos, de Bruno Seabra (1862)\n",
      "critica/mact08.txt: Pareceres - Conservatório Dramático (1862-1864)\n",
      "critica/mact09.txt: Homem de Mello e B. Pinheiro  A Constituinte perante a História e Sombras e Luz (1863)\n",
      "critica/mact10.txt: Peregrinação pela província de S. Paulo , por A. E. Zaluar (1863)\n",
      "critica/mact11.txt: Revelações , de A. E. Zaluar (1863)\n",
      "critica/mact12.txt: Dois folhetins. Suplício de uma mulher (1865)\n",
      "critica/mact13.txt: O Ideal do crítico (1865)\n",
      "critica/mact14.txt: Álvares de Azevedo: Lira dos vinte anos (1866)\n",
      "critica/mact15.txt: Crítica teatral (1866)\n",
      "critica/mact16.txt: Fagundes Varela  Cantos e fantasias (1866)\n",
      "critica/mact17.txt: J .M. de Macedo: O culto do dever (1866)\n",
      "critica/mact18.txt: José de Alencar: Iracema (1866)\n",
      "critica/mact19.txt: Junqueira Freire: Inspirações do claustro (1866)\n",
      "critica/mact20.txt: Porto Alegre: Colombo (1866)\n",
      "critica/mact21.txt: Propósito (1866)\n",
      "critica/mact22.txt: Castro Alves (1868)\n",
      "critica/mact23.txt: Lúcio de Mendonça: Névoas matutinas (1872)\n",
      "critica/mact24.txt: Un cuento endemoniado e La mujer misteriosa , de Guilherme Malta (1872)\n",
      "critica/mact25.txt: Notícia da atual literatura brasileira: Instinto de nacionalidade (1873)\n",
      "critica/mact26.txt: Fagundes Varela (1875)\n",
      "critica/mact27.txt: Eça de Queirós: O primo Basílio (1878)\n",
      "critica/mact28.txt: Francisco de Castro: Harmonias errantes (1878)\n",
      "critica/mact29.txt: A Nova geração (1879)\n",
      "critica/mact30.txt: Carlos Jansen: Contos seletos das mil e uma noites (1882)\n",
      "critica/mact31.txt: Raimundo Correia: Sinfonias (1882)\n",
      "critica/mact32.txt: Alberto de Oliveira: Meridionais (1884)\n",
      "critica/mact33.txt: Enéias Galvão: Miragens (1885)\n",
      "critica/mact34.txt: L. L. Fernandes Pinheiro Júnior: Tipos e quadros (1886)\n",
      "critica/mact35.txt: José de Alencar: O Guarani (1887)\n",
      "critica/mact36.txt: Henriqueta Renan (1896)\n",
      "critica/mact37.txt: Discursos na Academia Brasileira de Letras (1897)\n",
      "critica/mact38.txt: Magalhães de Azeredo: Procelárias (1898)\n",
      "critica/mact39.txt: Cenas da vida amazônica , de José Veríssimo (1899)\n",
      "critica/mact40.txt: Garrett (1899)\n",
      "critica/mact41.txt: Eça de Queirós (1900)\n",
      "critica/mact42.txt: Eduardo Prado (1901)\n",
      "critica/mact43.txt: Magalhães de Azeredo e Mário de Alencar: Horas sagradas e Versos (1902)\n",
      "critica/mact44.txt: Oliveira Lima: Secretário d'el-rei (1904)\n",
      "critica/mact45.txt: Joaquim Nabuco: Pensées détachées et souvenirs (1906)\n",
      "\n",
      "Miscelanea\n",
      "\n",
      "miscelanea/mams01.txt: Os imortais (1859)\n",
      "miscelanea/mams02.txt: Queda que as mulheres têm para os tolos (1861)\n",
      "miscelanea/mams03.txt: Carta ao Sr. Bispo do RJ (1862)\n",
      "miscelanea/mams04.txt: Carta à redação da Imprensa Acadêmica (1864)\n",
      "miscelanea/mams05.txt: Pedro Luís (1884)\n",
      "miscelanea/mams06.txt: A morte de Francisco Otaviano (1889)\n",
      "miscelanea/mams07.txt: Secretaria de Agricultura (1890)\n",
      "miscelanea/mams08.txt: A Paixão de Jesus (1904)\n",
      "miscelanea/mams09.txt: Gonçalves Dias (1906)\n",
      "miscelanea/mams10.txt: A Estátua de José de Alencar (1906)\n",
      "['contos/macn001.txt', 'contos/macn002.txt', 'contos/macn003.txt', 'contos/macn004.txt', 'contos/macn005.txt', 'contos/macn006.txt', 'contos/macn007.txt', 'contos/macn008.txt', 'contos/macn009.txt', 'contos/macn010.txt', 'contos/macn011.txt', 'contos/macn012.txt', 'contos/macn013.txt', 'contos/macn014.txt', 'contos/macn015.txt', 'contos/macn016.txt', 'contos/macn017.txt', 'contos/macn018.txt', 'contos/macn019.txt', 'contos/macn020.txt', 'contos/macn021.txt', 'contos/macn022.txt', 'contos/macn023.txt', 'contos/macn024.txt', 'contos/macn025.txt', 'contos/macn026.txt', 'contos/macn027.txt', 'contos/macn028.txt', 'contos/macn029.txt', 'contos/macn030.txt', 'contos/macn031.txt', 'contos/macn032.txt', 'contos/macn033.txt', 'contos/macn034.txt', 'contos/macn035.txt', 'contos/macn036.txt', 'contos/macn037.txt', 'contos/macn038.txt', 'contos/macn039.txt', 'contos/macn040.txt', 'contos/macn041.txt', 'contos/macn042.txt', 'contos/macn043.txt', 'contos/macn044.txt', 'contos/macn045.txt', 'contos/macn046.txt', 'contos/macn047.txt', 'contos/macn048.txt', 'contos/macn049.txt', 'contos/macn050.txt', 'contos/macn051.txt', 'contos/macn052.txt', 'contos/macn053.txt', 'contos/macn054.txt', 'contos/macn055.txt', 'contos/macn056.txt', 'contos/macn057.txt', 'contos/macn058.txt', 'contos/macn059.txt', 'contos/macn060.txt', 'contos/macn061.txt', 'contos/macn062.txt', 'contos/macn063.txt', 'contos/macn064.txt', 'contos/macn065.txt', 'contos/macn066.txt', 'contos/macn067.txt', 'contos/macn068.txt', 'contos/macn069.txt', 'contos/macn070.txt', 'contos/macn071.txt', 'contos/macn072.txt', 'contos/macn073.txt', 'contos/macn074.txt', 'contos/macn075.txt', 'contos/macn076.txt', 'contos/macn077.txt', 'contos/macn078.txt', 'contos/macn079.txt', 'contos/macn080.txt', 'contos/macn081.txt', 'contos/macn082.txt', 'contos/macn083.txt', 'contos/macn084.txt', 'contos/macn085.txt', 'contos/macn086.txt', 'contos/macn087.txt', 'contos/macn088.txt', 'contos/macn089.txt', 'contos/macn090.txt', 'contos/macn091.txt', 'contos/macn092.txt', 'contos/macn093.txt', 'contos/macn094.txt', 'contos/macn095.txt', 'contos/macn096.txt', 'contos/macn097.txt', 'contos/macn098.txt', 'contos/macn099.txt', 'contos/macn100.txt', 'contos/macn101.txt', 'contos/macn102.txt', 'contos/macn103.txt', 'contos/macn104.txt', 'contos/macn105.txt', 'contos/macn106.txt', 'contos/macn107.txt', 'contos/macn108.txt', 'contos/macn109.txt', 'contos/macn110.txt', 'contos/macn111.txt', 'contos/macn112.txt', 'contos/macn113.txt', 'contos/macn114.txt', 'contos/macn115.txt', 'contos/macn116.txt', 'contos/macn117.txt', 'contos/macn118.txt', 'contos/macn119.txt', 'contos/macn120.txt', 'contos/macn121.txt', 'contos/macn122.txt', 'contos/macn123.txt', 'contos/macn124.txt', 'contos/macn125.txt', 'contos/macn126.txt', 'contos/macn127.txt', 'contos/macn128.txt', 'contos/macn129.txt', 'contos/macn130.txt', 'contos/macn131.txt', 'contos/macn132.txt', 'contos/macn133.txt', 'contos/macn134.txt', 'contos/macn135.txt', 'contos/macn136.txt', 'contos/macn137.txt', 'critica/mact01.txt', 'critica/mact02.txt', 'critica/mact03.txt', 'critica/mact04.txt', 'critica/mact05.txt', 'critica/mact06.txt', 'critica/mact07.txt', 'critica/mact08.txt', 'critica/mact09.txt', 'critica/mact10.txt', 'critica/mact11.txt', 'critica/mact12.txt', 'critica/mact13.txt', 'critica/mact14.txt', 'critica/mact15.txt', 'critica/mact16.txt', 'critica/mact17.txt', 'critica/mact18.txt', 'critica/mact19.txt', 'critica/mact20.txt', 'critica/mact21.txt', 'critica/mact22.txt', 'critica/mact23.txt', 'critica/mact24.txt', 'critica/mact25.txt', 'critica/mact26.txt', 'critica/mact27.txt', 'critica/mact28.txt', 'critica/mact29.txt', 'critica/mact30.txt', 'critica/mact31.txt', 'critica/mact32.txt', 'critica/mact33.txt', 'critica/mact34.txt', 'critica/mact35.txt', 'critica/mact36.txt', 'critica/mact37.txt', 'critica/mact38.txt', 'critica/mact39.txt', 'critica/mact40.txt', 'critica/mact41.txt', 'critica/mact42.txt', 'critica/mact43.txt', 'critica/mact44.txt', 'critica/mact45.txt', 'cronica/macr01.txt', 'cronica/macr02.txt', 'cronica/macr03.txt', 'cronica/macr04.txt', 'cronica/macr05.txt', 'cronica/macr06.txt', 'cronica/macr07.txt', 'cronica/macr08.txt', 'cronica/macr09.txt', 'cronica/macr10.txt', 'cronica/macr11.txt', 'cronica/macr12.txt', 'cronica/macr13.txt', 'cronica/macr14.txt', 'cronica/macr15.txt', 'cronica/macr16.txt', 'cronica/macr17.txt', 'cronica/macr18.txt', 'cronica/macr19.txt', 'cronica/macr20.txt', 'cronica/macr21.txt', 'cronica/macr22.txt', 'cronica/macr23.txt', 'cronica/macr24.txt', 'miscelanea/mams01.txt', 'miscelanea/mams02.txt', 'miscelanea/mams03.txt', 'miscelanea/mams04.txt', 'miscelanea/mams05.txt', 'miscelanea/mams06.txt', 'miscelanea/mams07.txt', 'miscelanea/mams08.txt', 'miscelanea/mams09.txt', 'miscelanea/mams10.txt', 'poesia/maps01.txt', 'poesia/maps02.txt', 'poesia/maps03.txt', 'poesia/maps04.txt', 'poesia/maps05.txt', 'poesia/maps06.txt', 'poesia/maps07.txt', 'romance/marm01.txt', 'romance/marm02.txt', 'romance/marm03.txt', 'romance/marm04.txt', 'romance/marm05.txt', 'romance/marm06.txt', 'romance/marm07.txt', 'romance/marm08.txt', 'romance/marm09.txt', 'romance/marm10.txt', 'teatro/matt01.txt', 'teatro/matt02.txt', 'teatro/matt03.txt', 'teatro/matt04.txt', 'teatro/matt05.txt', 'teatro/matt06.txt', 'teatro/matt07.txt', 'teatro/matt08.txt', 'teatro/matt09.txt', 'teatro/matt10.txt', 'traducao/matr01.txt', 'traducao/matr02.txt', 'traducao/matr03.txt']"
     ]
    }
   ],
   "source": [
    "print(pyconvert(String, nltk.corpus.machado.readme()))\n",
    "print(nltk.corpus.machado.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c8b544-dd54-46ee-acf1-0c926778423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nltk.corpus.machado.raw(\"contos/macn076.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92374012-da3b-4b1e-bc3d-5615afb7d692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Romance, Dom Casmurro, 1899\\n\\nDom Casmurro\\n\\nTexto de referência:\\n\\nObras Completas de Machado de Assis,\\nvol. I,\\n\\nNova Aguilar, Rio de\\nJaneiro, 1994.\\n\\n Publicado originalmente\\npela Editora Garnier, Rio de Janeiro, 1899.\\n\\nCAPÍTULO PRIMEIRO\\n\\nDO TÍTULO\\n\\nUma noite destas, vindo da cidade\\npara o Engenho Novo, encontrei no trem da Central um rapaz aqui do bairro, que\\neu conheço de vista e de chapéu. Cumprimentou-me, sentou-se ao pé de mim, falou\\nda Lua e dos ministros, e acabou recitando-me versos. A viagem era curta, e os\\nversos pode ser que não fossem inteiramente maus. Sucedeu, porém, que, como eu\\nestava cansado, fechei os olhos três ou quatro vezes; tanto bastou para que ele\\ninterrompesse a leitura e metesse os versos no bolso.\\n\\n\\u97 Continue, disse eu acordando.\\n\\n\\u97 Já acabei, murmurou ele.\\n\\n\\u97 São muito bonitos.\\n\\nVi-lhe fazer um gesto para\\ntirá-los outra vez do bolso, mas não passou do gesto; estava amuado. No dia seguinte\\nentrou a dizer de mim nomes feios, e acabou alcunhando\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom_casmurro = pyconvert(String,nltk.corpus.machado.raw(\"romance/marm08.txt\"))[1:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e1c1d-e936-4cc0-a62d-c0b493680c78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Spacy\n",
    "\n",
    "Next, let's use spacy, another python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29ba9ba-2419-463f-a73e-c1c81fa80aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[1mPython module: \u001b[22m<module 'spacy' from '/home/davibarreira/Main/EMAp/Julia_Tutorials/NLP/.CondaPkg/env/lib/python3.10/site-packages/spacy/__init__.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy = pyimport(\"spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db938498-ef72-4258-8cf5-790373935c0f",
   "metadata": {},
   "source": [
    "Before going forward, we need to download the portuguese support in spacy.\n",
    "The following lines of code runs the commnad `python -m ...` with the current Conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e0931d-1388-4bd9-a8e2-8078a2f27356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CondaPkg.withenv() do\n",
    "#   run(`python -m spacy download pt_core_news_lg`)\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac0d5892-8867-4ebd-91bc-3a8088ec9d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{String}:\n",
       " \"Apple está querendo comprar uma startup do Reino Unido por 100 milhões de dólares\"\n",
       " \"Carros autônomos empurram a responsabilidade do seguro para os fabricantes.São Francisco considera banir os robôs de entrega que andam pelas calçadas\"\n",
       " \"Londres é a maior cidade do Reino Unido\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pyimport(\"spacy.lang.pt.examples\" => \"sentences\")\n",
    "\n",
    "sentences = pyconvert(Vector,sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d52915-ab10-4ab1-8292-8537bc382d21",
   "metadata": {},
   "source": [
    "## 1.3 Creating our Corpus\n",
    "\n",
    "We've showed how to get some samples using ntlk and spacy.\n",
    "Let's now create our working corpus, which will consist of\n",
    "the short-stories from Machado de Assis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c54d76f-297c-46e7-aeea-51cbc9d690da",
   "metadata": {},
   "outputs": [],
   "source": [
    "contos = [pyconvert(String,nltk.corpus.machado.raw(conto)) for conto in pyconvert(Vector,nltk.corpus.machado.fileids()) if startswith(conto,\"contos/\")];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef7414-f3b0-4f25-a824-bd4d1d0c1ef4",
   "metadata": {},
   "source": [
    "These texts are too large. Let's truncate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f042eb64-07dc-49d8-a2d8-33ac62c8253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conto, Contos Fluminenses, 1870\n",
      "\n",
      "Contos Fluminenses\n",
      "\n",
      "Texto-fonte:\n",
      "\n",
      "Obra Completa, Machado de Assis, vol. II,\n",
      "\n",
      "Rio de Janeiro: Nova Aguilar, 1994.\n",
      "\n",
      "Publicado originalmente pela\n",
      "Editora Garnier, Rio de Janeiro, em 1870.\n",
      "\n",
      "ÍNDICE\n",
      "\n",
      "MISS DOLLAR\n",
      "\n",
      "LUÍS\n",
      "SOARES\n",
      "\n",
      "A MULHER DE\n",
      "PRETO\n",
      "\n",
      "O\n",
      "SEGREDO DE AUGUSTA\n",
      "\n",
      "CONFISSÕES DE UMA VIÚVA MOÇA\n",
      "\n",
      "LINHA\n",
      "RETA E LINHA CURVA\n",
      "\n",
      "FREI\n",
      "SIMÃO\n",
      "\n",
      "MISS\n",
      "DOLLAR\n",
      "\n",
      "ÍNDICE\n",
      "\n",
      "Capítulo Primeiro\n",
      "\n",
      "Capítulo II\n",
      "\n",
      "Capítulo iii\n",
      "\n",
      "Capítulo iv\n",
      "\n",
      "Capítulo v\n",
      "\n",
      "Capítulo vI\n",
      "\n",
      "Capítulo vII\n",
      "\n",
      "CAPÍTULO VIII\n",
      "\n",
      "CAPÍTULO PRIMEIRO\n",
      "\n",
      "Era conveniente ao romance que o leitor\n",
      "ficasse muito tempo sem saber quem era Miss Dollar. Mas por outro lado,\n",
      "sem a apresentação de Miss Dollar, seria o autor obrigado a longas\n",
      "digressões, que encheriam o papel sem adiantar a ação. Não há hesitação\n",
      "possível: vou apresentar-lhes Miss Dollar.\n",
      "\n",
      "Se o leitor é rapaz e dado ao gênio\n",
      "melancólico, imagina que Miss Dollar é uma inglesa pálida e delgada,\n",
      "escassa de carnes e de sangue, abrindo à flor do rosto dois grandes olhos azuis\n",
      "e sac"
     ]
    }
   ],
   "source": [
    "contos = [first(conto,1000) for conto in contos]\n",
    "print(contos[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c9c65-cf5b-4553-a033-113cba400f10",
   "metadata": {},
   "source": [
    "# 2. Tokens & Stopwords & Lemmatizaion/Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21645a6-b701-42e0-809b-0959b877ec2c",
   "metadata": {},
   "source": [
    "When working with texts in portuguese, we might want to go with spacy instead of nltk. The reason for this is that spacy already comes with support for portuguese, enabling us to easily do lemmatization. \n",
    "\n",
    "As of now (2022), Julia still does not have packages that implement such things for texts in portuguese. Again showing the necessity of integration python with ou Julia script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68acf4-7731-4bd3-90d2-081b923349dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Now, let's tokenize our text**.\n",
    "\n",
    "Tokenization can be thought of as splitting a text into words. The tricky thing is,\n",
    "there are words such as \"Palo Alto\", which is actually a single name, hence,\n",
    "we want to treat it as a single \"token\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb7c5004-6479-4e90-a934-0d8cc7f4d145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1--------------------------------------\n",
      "Uma noite destas, vindo da cidade para o Engenho Novo,\n",
      "encontrei no trem da Central um rapaz aqui do bairro, que\n",
      "eu conheço de vista e de chapéu.\n",
      "2--------------------------------------\n",
      "Cumprimentou-me, sentou-se ao pé de mim, falou\n",
      "da Lua e dos ministros, e acabou recitando-me versos.\n",
      "3--------------------------------------\n",
      "A viagem era curta, e os\n",
      "versos pode ser que não fossem inteiramente maus.\n",
      "4--------------------------------------\n",
      "Sucedeu, porém, que, como eu\n",
      "estava cansado, fechei os olhos três ou quatro vezes; tanto bastou para que ele\n",
      "interrompesse a leitura e metesse os versos no bolso.\n"
     ]
    }
   ],
   "source": [
    "sent_tokenize, word_tokenize = pyimport(\"nltk.tokenize\" =>\n",
    "    (\"sent_tokenize\",\"word_tokenize\"));\n",
    "\n",
    "senttokenize(text) = pyconvert(Vector, sent_tokenize(text))\n",
    "wordtokenize(text) = pyconvert(Vector, word_tokenize(text))\n",
    "\n",
    "example = \"\"\"\n",
    "Uma noite destas, vindo da cidade para o Engenho Novo,\n",
    "encontrei no trem da Central um rapaz aqui do bairro, que\n",
    "eu conheço de vista e de chapéu. Cumprimentou-me, sentou-se ao pé de mim, falou\n",
    "da Lua e dos ministros, e acabou recitando-me versos. A viagem era curta, e os\n",
    "versos pode ser que não fossem inteiramente maus. Sucedeu, porém, que, como eu\n",
    "estava cansado, fechei os olhos três ou quatro vezes; tanto bastou para que ele\n",
    "interrompesse a leitura e metesse os versos no bolso.\n",
    "\"\"\"\n",
    "\n",
    "for (i,sentence) in enumerate(senttokenize(example))\n",
    "    println(i,\"--------------------------------------\")\n",
    "    println(sentence)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d37dc99-6e27-435c-a305-c18ccbdb5ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102-element Vector{String}:\n",
       " \"Uma\"\n",
       " \"noite\"\n",
       " \"destas\"\n",
       " \",\"\n",
       " \"vindo\"\n",
       " \"da\"\n",
       " \"cidade\"\n",
       " \"para\"\n",
       " \"o\"\n",
       " \"Engenho\"\n",
       " \"Novo\"\n",
       " \",\"\n",
       " \"encontrei\"\n",
       " ⋮\n",
       " \"que\"\n",
       " \"ele\"\n",
       " \"interrompesse\"\n",
       " \"a\"\n",
       " \"leitura\"\n",
       " \"e\"\n",
       " \"metesse\"\n",
       " \"os\"\n",
       " \"versos\"\n",
       " \"no\"\n",
       " \"bolso\"\n",
       " \".\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordtokenize(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca2450-cfe2-4c26-80c7-69bf9c33c05e",
   "metadata": {},
   "source": [
    "It (almost) worked. Note that we got almost everything correct.\n",
    "The only thing that seems wrong is the \"Engenho Novo\", which is a single\n",
    "location, and thus, it should be a single token. Yet,\n",
    "it's understandable that the code would not catch that.\n",
    "\n",
    "Let's now try with spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfb896d2-e890-4074-8123-4e2ff42b4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_lg\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d09098-a3e2-446a-9d0e-24e9290ff4f8",
   "metadata": {},
   "source": [
    "In spacy, if we run `nlp(example)`, this will run a whole pipeline. If we just want the tokenizer, we can do\n",
    "`nlt.tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05427ac6-6542-47b5-b406-3ef43eb46370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109-element Vector{String}:\n",
       " \"Uma\"\n",
       " \"noite\"\n",
       " \"destas\"\n",
       " \",\"\n",
       " \"vindo\"\n",
       " \"da\"\n",
       " \"cidade\"\n",
       " \"para\"\n",
       " \"o\"\n",
       " \"Engenho\"\n",
       " \"Novo\"\n",
       " \",\"\n",
       " \"\\n\"\n",
       " ⋮\n",
       " \"\\n\"\n",
       " \"interrompesse\"\n",
       " \"a\"\n",
       " \"leitura\"\n",
       " \"e\"\n",
       " \"metesse\"\n",
       " \"os\"\n",
       " \"versos\"\n",
       " \"no\"\n",
       " \"bolso\"\n",
       " \".\"\n",
       " \"\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp.tokenizer(example)\n",
    "tokens = [pyconvert(String,t.text) for t in pyconvert(Vector,collect(doc))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ad022-3d60-4ca8-8ba3-3128c890107a",
   "metadata": {},
   "source": [
    "The result from spacy is very similar to nltk. Yet, in this case,\n",
    "we got additionally `\\n`, the line break.\n",
    "\n",
    "Now we can tokeninze our corpus. Let's tokenize the whole text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11326845-efba-46fb-85e4-c65ce31bdea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [t for t in pyconvert(Vector,nltk.corpus.machado.fileids()) if startswith(t, \"contos/\")];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c68228be-aa52-4fe4-8a61-b3c3b0323b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:13\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "contos = [pyconvert(String,nltk.corpus.machado.raw(conto)) for conto in files]\n",
    "\n",
    "function truncatetokens(text,maxtokens = 1000)\n",
    "    doc = nlp.tokenizer(text)\n",
    "    tokens = [pyconvert(String,t.text) for t in pyconvert(Vector,collect(doc))][begin:min(end,maxtokens)]\n",
    "    # return join(tokens,\" \")\n",
    "end\n",
    "\n",
    "contos = @showprogress map(truncatetokens,contos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4397be2-eaa8-4452-b69f-a8570d7e53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "contos = join.(contos,\" \");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "847187e3-8f91-4f0c-9dda-3aed3789666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "stopwords = nltk.corpus.stopwords.words(\"portuguese\");\n",
    "stopwords = pyconvert(Vector,stopwords);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f20fbc-e15b-4b32-adb8-dc1af12a7a2e",
   "metadata": {},
   "source": [
    "## 3. Part-of-speech Tagging and Dependency Parsing.\n",
    "\n",
    "This task consists in tagging each word/token with it's grammatical morphology (e.g. subject, adverb, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9b9cd-76f4-4882-bf87-fab241896bc1",
   "metadata": {},
   "source": [
    "Let's start by running the spacy pipeline via the `nlp` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fdce0aa-a00d-4821-8da3-5c7c68e3eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:13\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "metacontos = @showprogress map(nlp,contos);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a4eb8-f706-4e64-86bb-2834b5202fc7",
   "metadata": {},
   "source": [
    "Once we've done this, our original corpus has been enriched with metadata.\n",
    "Let's put it in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "644ff8b5-c162-4493-bc98-980ff638dfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davibarreira/Main/EMAp/Julia_Tutorials/NLP/.CondaPkg/env/lib/python3.10/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'flat:name' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/davibarreira/Main/EMAp/Julia_Tutorials/NLP/.CondaPkg/env/lib/python3.10/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'acl:relcl' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/davibarreira/Main/EMAp/Julia_Tutorials/NLP/.CondaPkg/env/lib/python3.10/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'nsubj:pass' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/davibarreira/Main/EMAp/Julia_Tutorials/NLP/.CondaPkg/env/lib/python3.10/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'aux:pass' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/davibarreira/Main/EMAp/Julia_Tutorials/NLP/.CondaPkg/env/lib/python3.10/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'obl:agent' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/davibarreira/Main/EMAp/Julia_Tutorials/NLP/.CondaPkg/env/lib/python3.10/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'flat:foreign' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "df = Dict(\n",
    "    \"file\"=>[],\n",
    "    \"text\"=>[],\n",
    "    \"pos\"=>[],\n",
    "    \"pos_description\"=>[],\n",
    "    \"dep\"=>[],\n",
    "    \"dep_description\"=>[],\n",
    "    \"lemma\" =>[],\n",
    ")\n",
    "for (i,conto) in enumerate(metacontos)\n",
    "    for token in conto\n",
    "        push!(df[\"file\"],files[i])\n",
    "        push!(df[\"text\"],pyconvert(String,token.text))\n",
    "        push!(df[\"pos\"],pyconvert(String,token.pos_))\n",
    "        push!(df[\"pos_description\"],pyconvert(String,spacy.explain(token.pos_)))\n",
    "        push!(df[\"dep\"],pyconvert(String,token.dep_))\n",
    "        push!(df[\"lemma\"],pyconvert(String,token.lemma_))\n",
    "        try\n",
    "            push!(df[\"dep_description\"],pyconvert(String,spacy.explain(token.dep_)))\n",
    "        catch\n",
    "            push!(df[\"dep_description\"],\"\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "df = DataFrame(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a2bce6f-dd19-4472-b302-f403cae15463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>15,816 rows × 7 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>dep</th><th>dep_description</th><th>file</th><th>lemma</th><th>pos</th><th>pos_description</th><th>text</th></tr><tr><th></th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th></tr></thead><tbody><tr><th>1</th><td>ROOT</td><td>root</td><td>contos/macn001.txt</td><td>publicado</td><td>VERB</td><td>verb</td><td>Publicado</td></tr><tr><th>2</th><td>ROOT</td><td>root</td><td>contos/macn001.txt</td><td>vII</td><td>VERB</td><td>verb</td><td>vII</td></tr><tr><th>3</th><td>acl:relcl</td><td></td><td>contos/macn001.txt</td><td>ficar</td><td>VERB</td><td>verb</td><td>ficasse</td></tr><tr><th>4</th><td>advcl</td><td>adverbial clause modifier</td><td>contos/macn001.txt</td><td>saber</td><td>VERB</td><td>verb</td><td>saber</td></tr><tr><th>5</th><td>acl</td><td>clausal modifier of noun (adjectival clause)</td><td>contos/macn001.txt</td><td>obrigar</td><td>VERB</td><td>verb</td><td>obrigado</td></tr><tr><th>6</th><td>acl:relcl</td><td></td><td>contos/macn001.txt</td><td>encher</td><td>VERB</td><td>verb</td><td>encheriam</td></tr><tr><th>7</th><td>advcl</td><td>adverbial clause modifier</td><td>contos/macn001.txt</td><td>adiantar</td><td>VERB</td><td>verb</td><td>adiantar</td></tr><tr><th>8</th><td>ROOT</td><td>root</td><td>contos/macn001.txt</td><td>haver</td><td>VERB</td><td>verb</td><td>há</td></tr><tr><th>9</th><td>parataxis</td><td>parataxis</td><td>contos/macn001.txt</td><td>apresentar-lhes</td><td>VERB</td><td>verb</td><td>apresentar-lhes</td></tr><tr><th>10</th><td>conj</td><td>conjunct</td><td>contos/macn001.txt</td><td>dar</td><td>VERB</td><td>verb</td><td>dado</td></tr><tr><th>11</th><td>ROOT</td><td>root</td><td>contos/macn001.txt</td><td>imaginar</td><td>VERB</td><td>verb</td><td>imagina</td></tr><tr><th>12</th><td>conj</td><td>conjunct</td><td>contos/macn001.txt</td><td>delgar</td><td>VERB</td><td>verb</td><td>delgada</td></tr><tr><th>13</th><td>advcl</td><td>adverbial clause modifier</td><td>contos/macn001.txt</td><td>abrir</td><td>VERB</td><td>verb</td><td>abrindo</td></tr><tr><th>14</th><td>conj</td><td>conjunct</td><td>contos/macn001.txt</td><td>sacudir</td><td>VERB</td><td>verb</td><td>sacudindo</td></tr><tr><th>15</th><td>ROOT</td><td>root</td><td>contos/macn001.txt</td><td>dever</td><td>VERB</td><td>verb</td><td>deve</td></tr><tr><th>16</th><td>conj</td><td>conjunct</td><td>contos/macn001.txt</td><td>dever</td><td>VERB</td><td>verb</td><td>deve</td></tr><tr><th>17</th><td>acl:relcl</td><td></td><td>contos/macn001.txt</td><td>alimentar</td><td>VERB</td><td>verb</td><td>alimenta</td></tr><tr><th>18</th><td>ROOT</td><td>root</td><td>contos/macn001.txt</td><td>dever</td><td>VERB</td><td>verb</td><td>deve</td></tr><tr><th>19</th><td>xcomp</td><td>open clausal complement</td><td>contos/macn001.txt</td><td>ter</td><td>VERB</td><td>verb</td><td>ter</td></tr><tr><th>20</th><td>conj</td><td>conjunct</td><td>contos/macn001.txt</td><td>ler</td><td>VERB</td><td>verb</td><td>ler</td></tr><tr><th>21</th><td>advcl</td><td>adverbial clause modifier</td><td>contos/macn001.txt</td><td>saber</td><td>VERB</td><td>verb</td><td>souber</td></tr><tr><th>22</th><td>parataxis</td><td>parataxis</td><td>contos/macn001.txt</td><td>dever</td><td>VERB</td><td>verb</td><td>deve</td></tr><tr><th>23</th><td>xcomp</td><td>open clausal complement</td><td>contos/macn001.txt</td><td>deliciar se</td><td>VERB</td><td>verb</td><td>deliciar-se</td></tr><tr><th>24</th><td>ROOT</td><td>root</td><td>contos/macn001.txt</td><td>dever</td><td>VERB</td><td>verb</td><td>devem</td></tr><tr><th>25</th><td>conj</td><td>conjunct</td><td>contos/macn001.txt</td><td>adicionando-se-lhe</td><td>VERB</td><td>verb</td><td>adicionando-se-lhe</td></tr><tr><th>26</th><td>advcl</td><td>adverbial clause modifier</td><td>contos/macn001.txt</td><td>acudir</td><td>VERB</td><td>verb</td><td>acudir</td></tr><tr><th>27</th><td>ROOT</td><td>root</td><td>contos/macn001.txt</td><td>dever</td><td>VERB</td><td>verb</td><td>deve</td></tr><tr><th>28</th><td>ROOT</td><td>root</td><td>contos/macn001.txt</td><td>Suponhamos</td><td>VERB</td><td>verb</td><td>Suponhamos</td></tr><tr><th>29</th><td>ccomp</td><td>clausal complement</td><td>contos/macn001.txt</td><td>dar</td><td>VERB</td><td>verb</td><td>dado</td></tr><tr><th>30</th><td>acl:relcl</td><td></td><td>contos/macn001.txt</td><td>imaginar</td><td>VERB</td><td>verb</td><td>imagina</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& dep & dep\\_description & file & lemma & pos & pos\\_description & text\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any & Any & Any & Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & ROOT & root & contos/macn001.txt & publicado & VERB & verb & Publicado \\\\\n",
       "\t2 & ROOT & root & contos/macn001.txt & vII & VERB & verb & vII \\\\\n",
       "\t3 & acl:relcl &  & contos/macn001.txt & ficar & VERB & verb & ficasse \\\\\n",
       "\t4 & advcl & adverbial clause modifier & contos/macn001.txt & saber & VERB & verb & saber \\\\\n",
       "\t5 & acl & clausal modifier of noun (adjectival clause) & contos/macn001.txt & obrigar & VERB & verb & obrigado \\\\\n",
       "\t6 & acl:relcl &  & contos/macn001.txt & encher & VERB & verb & encheriam \\\\\n",
       "\t7 & advcl & adverbial clause modifier & contos/macn001.txt & adiantar & VERB & verb & adiantar \\\\\n",
       "\t8 & ROOT & root & contos/macn001.txt & haver & VERB & verb & há \\\\\n",
       "\t9 & parataxis & parataxis & contos/macn001.txt & apresentar-lhes & VERB & verb & apresentar-lhes \\\\\n",
       "\t10 & conj & conjunct & contos/macn001.txt & dar & VERB & verb & dado \\\\\n",
       "\t11 & ROOT & root & contos/macn001.txt & imaginar & VERB & verb & imagina \\\\\n",
       "\t12 & conj & conjunct & contos/macn001.txt & delgar & VERB & verb & delgada \\\\\n",
       "\t13 & advcl & adverbial clause modifier & contos/macn001.txt & abrir & VERB & verb & abrindo \\\\\n",
       "\t14 & conj & conjunct & contos/macn001.txt & sacudir & VERB & verb & sacudindo \\\\\n",
       "\t15 & ROOT & root & contos/macn001.txt & dever & VERB & verb & deve \\\\\n",
       "\t16 & conj & conjunct & contos/macn001.txt & dever & VERB & verb & deve \\\\\n",
       "\t17 & acl:relcl &  & contos/macn001.txt & alimentar & VERB & verb & alimenta \\\\\n",
       "\t18 & ROOT & root & contos/macn001.txt & dever & VERB & verb & deve \\\\\n",
       "\t19 & xcomp & open clausal complement & contos/macn001.txt & ter & VERB & verb & ter \\\\\n",
       "\t20 & conj & conjunct & contos/macn001.txt & ler & VERB & verb & ler \\\\\n",
       "\t21 & advcl & adverbial clause modifier & contos/macn001.txt & saber & VERB & verb & souber \\\\\n",
       "\t22 & parataxis & parataxis & contos/macn001.txt & dever & VERB & verb & deve \\\\\n",
       "\t23 & xcomp & open clausal complement & contos/macn001.txt & deliciar se & VERB & verb & deliciar-se \\\\\n",
       "\t24 & ROOT & root & contos/macn001.txt & dever & VERB & verb & devem \\\\\n",
       "\t25 & conj & conjunct & contos/macn001.txt & adicionando-se-lhe & VERB & verb & adicionando-se-lhe \\\\\n",
       "\t26 & advcl & adverbial clause modifier & contos/macn001.txt & acudir & VERB & verb & acudir \\\\\n",
       "\t27 & ROOT & root & contos/macn001.txt & dever & VERB & verb & deve \\\\\n",
       "\t28 & ROOT & root & contos/macn001.txt & Suponhamos & VERB & verb & Suponhamos \\\\\n",
       "\t29 & ccomp & clausal complement & contos/macn001.txt & dar & VERB & verb & dado \\\\\n",
       "\t30 & acl:relcl &  & contos/macn001.txt & imaginar & VERB & verb & imagina \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m15816×7 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m dep       \u001b[0m\u001b[1m dep_description                   \u001b[0m\u001b[1m file               \u001b[0m\u001b[1m lemma           \u001b[0m\u001b[1m pos  \u001b[0m\u001b[1m pos_description \u001b[0m\u001b[1m text            \u001b[0m\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Any       \u001b[0m\u001b[90m Any                               \u001b[0m\u001b[90m Any                \u001b[0m\u001b[90m Any             \u001b[0m\u001b[90m Any  \u001b[0m\u001b[90m Any             \u001b[0m\u001b[90m Any             \u001b[0m\n",
       "───────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "     1 │ ROOT       root                               contos/macn001.txt  publicado        VERB  verb             Publicado\n",
       "     2 │ ROOT       root                               contos/macn001.txt  vII              VERB  verb             vII\n",
       "     3 │ acl:relcl                                     contos/macn001.txt  ficar            VERB  verb             ficasse\n",
       "     4 │ advcl      adverbial clause modifier          contos/macn001.txt  saber            VERB  verb             saber\n",
       "     5 │ acl        clausal modifier of noun (adject…  contos/macn001.txt  obrigar          VERB  verb             obrigado\n",
       "     6 │ acl:relcl                                     contos/macn001.txt  encher           VERB  verb             encheriam\n",
       "     7 │ advcl      adverbial clause modifier          contos/macn001.txt  adiantar         VERB  verb             adiantar\n",
       "     8 │ ROOT       root                               contos/macn001.txt  haver            VERB  verb             há\n",
       "     9 │ parataxis  parataxis                          contos/macn001.txt  apresentar-lhes  VERB  verb             apresentar-lhes\n",
       "    10 │ conj       conjunct                           contos/macn001.txt  dar              VERB  verb             dado\n",
       "    11 │ ROOT       root                               contos/macn001.txt  imaginar         VERB  verb             imagina\n",
       "   ⋮   │     ⋮                      ⋮                          ⋮                  ⋮          ⋮           ⋮                ⋮\n",
       " 15807 │ ROOT       root                               contos/macn137.txt  saber            VERB  verb             sabemos\n",
       " 15808 │ parataxis  parataxis                          contos/macn137.txt  saber            VERB  verb             sabemos\n",
       " 15809 │ parataxis  parataxis                          contos/macn137.txt  acrescenter      VERB  verb             acrescentemos\n",
       " 15810 │ ROOT       root                               contos/macn137.txt  imagine          VERB  verb             imagine\n",
       " 15811 │ advcl      adverbial clause modifier          contos/macn137.txt  enfronhar        VERB  verb             enfronhando\n",
       " 15812 │ advcl      adverbial clause modifier          contos/macn137.txt  saber            VERB  verb             sabia\n",
       " 15813 │ ROOT       root                               contos/macn137.txt  gostar           VERB  verb             gostava\n",
       " 15814 │ xcomp      open clausal complement            contos/macn137.txt  andar            VERB  verb             andar\n",
       " 15815 │ parataxis  parataxis                          contos/macn137.txt  usar             VERB  verb             usava\n",
       " 15816 │ advcl      adverbial clause modifier          contos/macn137.txt  pedir            VERB  verb             pedir\n",
       "\u001b[36m                                                                                                                 15795 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter(row->row[:pos_description] == \"verb\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a5ba0e4-7871-4f27-b79b-683d659ca80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "São Paulo\n",
      "Luís Soares\n"
     ]
    }
   ],
   "source": [
    "for chunk in nlp(\"São Paulo é uma bela cidade. Luís Soares é um morador de lá.\").noun_chunks\n",
    "    println(chunk)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9772c0cc-b98a-4975-a928-c574e2456d7b",
   "metadata": {},
   "source": [
    "# 4.Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "439034dc-1d15-4c47-b7bf-c09f284a6460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[1mPython Doc: \u001b[22mApple está querendo comprar uma startup do Reino Unido por 100 milhões de dólares"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15967eca-7b81-4cb7-a3e5-1d6c2e4d18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "ORG\n",
      "0-5\n",
      "-----------------------\n",
      "Reino Unido\n",
      "LOC\n",
      "43-54\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "for token in doc.ents\n",
    "    println(token.text)\n",
    "    println(token.label_)\n",
    "    println(token.start_char,\"-\", token.end_char)\n",
    "    println(\"-----------------------\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee6eb6-62b5-4e79-978f-f57e8a173b93",
   "metadata": {},
   "source": [
    "# 5. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc68ac3-53e3-4b7d-87e3-2bbac4c0ea1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (4 threads) 1.7.2",
   "language": "julia",
   "name": "julia-(4-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
